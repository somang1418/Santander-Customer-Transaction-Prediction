{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "69954ccbb6d42e51269260d8e2a8fe7228e04a50"
   },
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "\n",
    "# **What Is Bayesian Optimization and Why Do We Care?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b387c0ff9fb2ade4c5365c6bc02c8ef96d515b9f"
   },
   "source": [
    "**Bayesian Optimization** is a probabilistic model based approach for finding the minimum of any function that returns a real-value metric. [(source)](https://towardsdatascience.com/an-introductory-example-of-bayesian-optimization-in-python-with-hyperopt-aae40fff4ff0)<br> It is very effective with real-world applications in high-dimensional parameter-tuning for complex machine learning algorithms. Bayesian optimization utilizes the Bayesian technique of setting a prior over the objective function and\n",
    "combining it with evidence to get a posterior function. I attached one graph that demonstrates Bayes’ theorem below. <br> <br>\n",
    "\n",
    "<img src=\"https://www.analyticsvidhya.com/wp-content/uploads/2016/06/12-768x475.jpg\"  alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "<br> <br> \n",
    " The prior belief is our belief in parameters before modeling process. The posterior belief is our belief in our parameters after observing the evidence.\n",
    "<br> Another way to present the Bayes’ theorem is: \n",
    "\n",
    "<img src=\"https://www.maths.ox.ac.uk/system/files/attachments/Bayes_0.png\"  alt=\"Drawing\" style=\"width: 600px;\"/> <br> \n",
    "\n",
    "For continuous functions, Bayesian optimization typically works by assuming the unknown function was sampled from a Gaussian process and maintains a posterior distribution for this function as observations are made, which means that we need to give range of values of hyperparameters (ex. learning rate range from 0.1 to 1).  So, in our case, the Gaussian process gives us a prior distribution on functions. Gaussian process approach is a non-parametric approach, in that it finds a distribution over the possible functions \n",
    "f(x) that are consistent with the observed data. Gaussian processes have proven to be useful surrogate models for computer experiments and good\n",
    "practices have been established in this context for sensitivity analysis, calibration and prediction While these strategies are not considered in the context of optimization, they can be useful to researchers in machine learning who wish to understand better the sensitivity of their models to various hyperparameters. [(source)](http://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf)\n",
    "\n",
    "<br>\n",
    "**Well..why do we care about it?** <br> \n",
    "According to the [study](http://proceedings.mlr.press/v28/bergstra13.pdf), hyperparameter tuning by Bayesian Optimization of machine learnin models is more efficient than Grid Search and Random Search. Bayesian Optimization has better overall performance on the test data and takes less time for optimization. Also, we do not need to set a certain values of parameters like we do in Random Search and Grid Search. For Bayesian Optimization tuning, we just give a range of a hyperparameter. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "44e3d052e7977441be8ce913532021d36e902884"
   },
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "# **Loading Library and Dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#basic tools \n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "#tuning hyperparameters\n",
    "from bayes_opt import BayesianOptimization\n",
    "from skopt  import BayesSearchCV \n",
    "\n",
    "#graph, plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#building models\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "import time\n",
    "import sys\n",
    "\n",
    "#metrics \n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import shap\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "de9279f02cb62dab5f485b915225730f2e0177f7"
   },
   "source": [
    "By Changing the data type of each column, I reduced memory usages by 75%. By taking the minimum and the maximum of each column, the function assigns which numeric data type is optimal for the column and change the data type. If you want to know more about how it works, I suggest you to read [Eryk's article](https://towardsdatascience.com/make-working-with-large-dataframes-easier-at-least-for-your-memory-6f52b5f4b5c4)! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "bfb1d1eac5f3a3bf038a87f898554a24dc2ea701"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int8','int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 78.01 Mb (74.7% reduction)\n",
      "Mem. usage decreased to 77.82 Mb (74.6% reduction)\n",
      "Shape of train set:  (200000, 202)\n",
      "Shape of test set:  (200000, 201)\n",
      "CPU times: user 31.3 s, sys: 31.8 s, total: 1min 3s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train= reduce_mem_usage(pd.read_csv(\"../input/train.csv\"))\n",
    "test= reduce_mem_usage(pd.read_csv(\"../input/test.csv\"))\n",
    "print(\"Shape of train set: \",train.shape)\n",
    "print(\"Shape of test set: \",test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
